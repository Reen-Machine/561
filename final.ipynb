{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "TBsgLNcrPWkm"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "n7VxbPCiPYam"
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_dir, labels_file=None, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        if labels_file:\n",
    "            # Load labels and filenames from the CSV file\n",
    "            self.labels_df = pd.read_csv(labels_file, names=['filename', 'label'])\n",
    "        else:\n",
    "            # For test dataset, only load filenames\n",
    "            self.filenames = os.listdir(data_dir)\n",
    "\n",
    "    def __len__(self):\n",
    "        if hasattr(self, 'labels_df'):\n",
    "            return len(self.labels_df)\n",
    "        else:\n",
    "            return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if hasattr(self, 'labels_df'):\n",
    "            img_name = self.labels_df.iloc[idx, 0]  # Get filename from CSV\n",
    "            label = self.labels_df.iloc[idx, 1]# Get label from CSV\n",
    "        else:\n",
    "            img_name = self.filenames[idx]  # Get filename for test dataset\n",
    "            label = None\n",
    "        if not img_name.endswith('.jpg'):\n",
    "            img_name += '.jpg'\n",
    "        img_path = os.path.join(self.data_dir, img_name)\n",
    "\n",
    "        try:\n",
    "            image = Image.open(img_path).convert(\"RGB\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Warning: File not found: {img_path}\")\n",
    "            return None, None\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        if image is None:\n",
    "            return None, None  # Return None for both image and label if loading fails\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "vTbtf3-cPcbM"
   },
   "outputs": [],
   "source": [
    "# Define data transformations\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 352
    },
    "id": "FPcA1GYNPemm",
    "outputId": "18f22f62-3851-491f-d32c-ca71ca655c4b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryan_benvenuti_uri_edu/.conda/envs/pytorch/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/ryan_benvenuti_uri_edu/.conda/envs/pytorch/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Create datasets\n",
    "dataset = CustomDataset(data_dir='/home/ryan_benvenuti_uri_edu/ondemand/data/sys/dashboard/batch_connect/sys/bc_jupyter/output/561/train/train', labels_file='/home/ryan_benvenuti_uri_edu/ondemand/data/sys/dashboard/batch_connect/sys/bc_jupyter/output/561/train_labels.csv', transform=data_transforms['train'])\n",
    "train_dataset, valid_dataset = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "#test_dataset = CustomDataset(data_dir='home/ryan_benvenuti_uri_edu/ondemand/data/sys/dashboard/batch_connect/sys/bc_jupyter/output/87e02b46-5bd9-428a-a86a-c7093ea737b4/A3/test_files', transform=data_transforms['test'])\n",
    "#test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# Load pre-trained ResNet50\n",
    "model = models.resnet50(pretrained=True)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 2)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"gpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "uZRRqZMqPhpm"
   },
   "outputs": [],
   "source": [
    "# Training loop\n",
    "def train(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    total_samples = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = torch.tensor(labels).to(device)  # Convert labels to tensor and move to device\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        total_samples += inputs.size(0)\n",
    "    return running_loss / total_samples\n",
    "\n",
    "# Validation loop\n",
    "def validate(model, valid_loader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in valid_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "FtoIDMZYQzMH"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1517524/3061448965.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(labels).to(device)  # Convert labels to tensor and move to device\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Training Loss: 0.0990, Validation Accuracy: 0.9973\n",
      "Epoch 2/10, Training Loss: 0.0110, Validation Accuracy: 0.9987\n",
      "Epoch 3/10, Training Loss: 0.0049, Validation Accuracy: 0.9982\n",
      "Epoch 4/10, Training Loss: 0.0042, Validation Accuracy: 0.9987\n",
      "Epoch 5/10, Training Loss: 0.0025, Validation Accuracy: 0.9982\n",
      "Epoch 6/10, Training Loss: 0.0023, Validation Accuracy: 0.9987\n",
      "Epoch 7/10, Training Loss: 0.0017, Validation Accuracy: 0.9982\n",
      "Epoch 8/10, Training Loss: 0.0013, Validation Accuracy: 0.9987\n",
      "Epoch 9/10, Training Loss: 0.0013, Validation Accuracy: 0.9987\n",
      "Epoch 10/10, Training Loss: 0.0006, Validation Accuracy: 0.9987\n"
     ]
    }
   ],
   "source": [
    "# Training and validation\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train(model, train_loader, criterion, optimizer, device)\n",
    "    valid_accuracy = validate(model, valid_loader, device)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {train_loss:.4f}, Validation Accuracy: {valid_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4RIi0-bIQ2ZP"
   },
   "outputs": [],
   "source": [
    "# Define custom dataset for testing without labels\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(os.listdir(self.data_dir))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.listdir(self.data_dir)[idx]\n",
    "        img_path = os.path.join(self.data_dir, img_name)\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "# Test function\n",
    "def test(model, test_data, device):\n",
    "    model.eval()\n",
    "    test_predictions = []\n",
    "    with torch.no_grad():\n",
    "        for inputs in test_data:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            test_predictions.append(outputs.cpu())\n",
    "    return torch.cat(test_predictions, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "meuqj0Fgk4Af"
   },
   "outputs": [],
   "source": [
    "# Create test dataset and data loader\n",
    "test_dataset = TestDataset(data_dir='test_data', transform=data_transforms['test'])\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# Testing\n",
    "test_predictions = test(model, test_loader, device)\n",
    "\n",
    "# Save test predictions to a .pt file\n",
    "torch.save(test_predictions, 'prediction.pt')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:.conda-pytorch]",
   "language": "python",
   "name": "conda-env-.conda-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
